<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 3 - CS180 Portfolio</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
            color: #333;
            margin: 0;
            background-image: url('../assets/images/background.jpg');
            background-attachment: fixed;
            background-size: cover;
            background-position: center;
            min-height: 100vh;
            box-sizing: border-box;
        }
        .container {
            max-width: 1000px;
            margin: 40px auto 80px;
            padding: 20px;
            background: rgba(255, 255, 255, 0.9);
            border-radius: 8px;
        }
        header {
            text-align: center;
            margin-bottom: 40px;
        }
        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        header p {
            color: #6c757d;
        }
        .project-section {
            margin-bottom: 40px;
        }
        .project-section h2 {
            border-bottom: 2px solid #e9ecef;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        .three-col-gallery {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 20px;
            align-items: start;
        }
        .result-item img {
            width: 100%;
            border-radius: 8px;
            border: 1px solid #ddd;
        }
        .result-item figcaption {
            font-size: 0.9em;
            color: #6c757d;
            margin-top: 10px;
            text-align: center;
        }
        .results-gallery {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            align-items: start;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: center;
        }
        th {
            background-color: #f2f2f2;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        .matrix-container {
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 20px 0;
        }
        .matrix-table {
            position: relative;
            display: inline-block;
            padding: 0 10px;
        }
        .matrix-table::before, .matrix-table::after {
            content: "";
            position: absolute;
            top: 0;
            bottom: 0;
            width: 2px;
            background-color: #333;
        }
        .matrix-table::before {
            left: 0;
            border-top: 2px solid #333;
            border-bottom: 2px solid #333;
        }
        .matrix-table::after {
            right: 0;
            border-top: 2px solid #333;
            border-bottom: 2px solid #333;
        }
        .matrix-table table {
            border-collapse: collapse;
            margin: 0;
        }
        .matrix-table td {
            border: none;
            padding: 5px 10px;
            text-align: right;
            font-family: 'Courier New', Courier, monospace;
        }
        .pixelated {
            image-rendering: pixelated;
            image-rendering: crisp-edges;
        }
        .single-image-container {
            text-align: center;
            margin: 20px auto;
            max-width: 75%;
        }
        .single-image-container img {
            width: 100%;
            border-radius: 8px;
            border: 1px solid #ddd;
        }
        footer {
            text-align: center;
            margin-top: 40px;
            color: #6c757d;
            font-size: 0.9em;
        }
        .back-link {
            display: block;
            text-align: center;
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-link">Back to Portfolio</a>
        <header>
            <h1>Project 3: Image Mosaicing</h1>
        </header>
        <p>In this project, I wrote code to warp images onto other projection planes, and blending them together as if they were captured from the same "angle".
            <br>
            I also wrote code to find point correspondences between images, which are inputs to the function to find the homography between images.
            <br>
            One unexpected significant difficulty was actually the inconsistent definitions of the coordinates with different functions (such as which axis is the x-axis, which axis is the y-axis, and where is the origin). I learned to carefully evaluate the convention used whenever I use anything built-in, such as plt.ginput or plt.scatter.
        </p>

        <main>
            <section class="project-section">
                <h2>A.1: Shooting the Pictures</h2>
                <p>For the images, I captured them using my own phone, at 1x zoom for all images.
                    I took pictures sequentially by fixing the vertical axis through my camera lens with my left hand, and then using my right hand to spin my phone around that axis.
                    This ensures that the position of my camera doesn't change, which is important to ensure that my images are still related by homographies, especially when some of the scenes have depth (is three dimensional).
                </p>

                <h3>Set 1</h3>
                <div class="three-col-gallery">
                    <figure class="result-item">
                        <img src="./assets/sets/set1/1.jpg" alt="Set 1, Image 1">
                        <figcaption>Warren 1</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set1/2.jpg" alt="Set 1, Image 2">
                        <figcaption>Warren 2</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set1/3.jpg" alt="Set 1, Image 3">
                        <figcaption>Warren 3</figcaption>
                    </figure>
                </div>

                <h3>Set 2</h3>
                <div class="three-col-gallery">
                    <figure class="result-item">
                        <img src="./assets/sets/set2/1.jpg" alt="Set 2, Image 1">
                        <figcaption>BNorth 1</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set2/2.jpg" alt="Set 2, Image 2">
                        <figcaption>BNorth 2</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set2/3.jpg" alt="Set 2, Image 3">
                        <figcaption>BNorth 3</figcaption>
                    </figure>
                </div>

                <h3>Set 3</h3>
                <div class="three-col-gallery">
                    <figure class="result-item">
                        <img src="./assets/sets/set3/1.jpg" alt="Set 3, Image 1">
                        <figcaption>Dwinelle 1</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set3/2.jpg" alt="Set 3, Image 2">
                        <figcaption>Dwinelle 2</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set3/3.jpg" alt="Set 3, Image 3">
                        <figcaption>Dwinelle 3</figcaption>
                    </figure>
                </div>
            </section>

            <section class="project-section">
                <h2>A.2: Recovering Homographies</h2>
                <p>The images I took, because the position of the camera didn't change, are related by homographies.
                    To project an image to the plane of another, I just need to calculate the homography based on some point correspondences between the images, and then apply the homography to the image.
                    <br>
                    Homographies have 8 degrees of freedom, so I needed at minimum 4 pairs of points (8 equations).
                    However, to make the system more robust, I allowed for having more than 4 pairs of points (where I would solve the overdetermined system using least squares).
                    See an example of this below.
                </p>

                <h3>Visualizing Correspondences</h3>
                <p>Points in the images are labeled with red crosses; please zoom in to see them more clearly (they are usually at corners).</p>
                <div class="results-gallery">
                    <figure class="result-item">
                        <img src="./assets/A.2/1.png" alt="Correspondence Set 1">
                        <figcaption>Image 1</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/A.2/2.png" alt="Correspondence Set 2">
                        <figcaption>Image 2</figcaption>
                    </figure>
                </div>

                <h3>Point Correspondences</h3>
                <p>The same correspondences, represented in numbers. The origin is the top left corner, with X growing downwards and Y growing rightwards, as per the usual convention for images.</p>
                <div style="display: flex; gap: 20px;">
                    <div style="flex: 1;">
                        <h4>Image 1 Points</h4>
                        <table>
                            <thead><tr><th>X</th><th>Y</th></tr></thead>
                            <tbody>
                                <tr><td>458.2</td><td>614.8</td></tr>
                                <tr><td>976.8</td><td>618.7</td></tr>
                                <tr><td>452.3</td><td>710.3</td></tr>
                                <tr><td>434.8</td><td>952.0</td></tr>
                                <tr><td>988.5</td><td>725.9</td></tr>
                                <tr><td>1019.7</td><td>955.9</td></tr>
                                <tr><td>452.3</td><td>1032.0</td></tr>
                                <tr><td>411.4</td><td>1614.9</td></tr>
                                <tr><td>776.0</td><td>1039.8</td></tr>
                                <tr><td>795.5</td><td>1614.9</td></tr>
                                <tr><td>1021.6</td><td>1299.1</td></tr>
                            </tbody>
                        </table>
                    </div>
                    <div style="flex: 1;">
                        <h4>Image 2 Points</h4>
                        <table>
                            <thead><tr><th>X</th><th>Y</th></tr></thead>
                            <tbody>
                                <tr><td>425.1</td><td>20.1</td></tr>
                                <tr><td>1047.0</td><td>24.0</td></tr>
                                <tr><td>427.0</td><td>152.7</td></tr>
                                <tr><td>430.9</td><td>447.1</td></tr>
                                <tr><td>1050.9</td><td>170.3</td></tr>
                                <tr><td>1048.9</td><td>447.1</td></tr>
                                <tr><td>454.3</td><td>540.7</td></tr>
                                <tr><td>460.1</td><td>1047.6</td></tr>
                                <tr><td>787.7</td><td>542.6</td></tr>
                                <tr><td>785.7</td><td>1041.7</td></tr>
                                <tr><td>1004.1</td><td>788.3</td></tr>
                            </tbody>
                        </table>
                    </div>
                </div>

                <h3>System of Equations (Ah=b)</h3>
                <p>For setting up least squares, I used the setup from discussion.
                    (I also re-derived it, just by setting the resulting X and Y coordinates of the homography for each input point to be equal to the associated output point's coordinates).
                    Here, h is the 8 parameters of the homography matrix (with the bottom right entry set to 1) flattened into a vector.
                    <br>
                    Note that I set up the equations such that image1 will be projected onto the plane of image2.
                </p>
                <div class="matrix-container" style="overflow-x: auto; justify-content: center;">
                    <div class="matrix-table">
                        <table>
                            <tbody>
                                <tr><td>458.2</td><td>614.8</td><td>1</td><td>0</td><td>0</td><td>0</td><td>-1.95e+05</td><td>-2.61e+05</td></tr>
                                <tr><td>0</td><td>0</td><td>0</td><td>458.2</td><td>614.8</td><td>1</td><td>-9.23e+03</td><td>-1.24e+04</td></tr>
                                <tr><td>976.8</td><td>618.7</td><td>1</td><td>0</td><td>0</td><td>0</td><td>-1.02e+06</td><td>-6.48e+05</td></tr>
                                <tr><td>0</td><td>0</td><td>0</td><td>976.8</td><td>618.7</td><td>1</td><td>-2.35e+04</td><td>-1.49e+04</td></tr>
                                <tr><td>452.3</td><td>710.3</td><td>1</td><td>0</td><td>0</td><td>0</td><td>-1.93e+05</td><td>-3.03e+05</td></tr>
                                <tr><td>0</td><td>0</td><td>0</td><td>452.3</td><td>710.3</td><td>1</td><td>-6.91e+04</td><td>-1.08e+05</td></tr>
                                <tr><td>434.8</td><td>952.0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>-1.87e+05</td><td>-4.10e+05</td></tr>
                                <tr><td>0</td><td>0</td><td>0</td><td>434.8</td><td>952.0</td><td>1</td><td>-1.94e+05</td><td>-4.26e+05</td></tr>
                                <tr><td>988.5</td><td>725.9</td><td>1</td><td>0</td><td>0</td><td>0</td><td>-1.04e+06</td><td>-7.63e+05</td></tr>
                                <tr><td>0</td><td>0</td><td>0</td><td>988.5</td><td>725.9</td><td>1</td><td>-1.68e+05</td><td>-1.24e+05</td></tr>
                                <tr><td>1019.7</td><td>955.9</td><td>1</td><td>0</td><td>0</td><td>0</td><td>-1.07e+06</td><td>-1.00e+06</td></tr>
                                <tr><td>0</td><td>0</td><td>0</td><td>1019.7</td><td>955.9</td><td>1</td><td>-4.56e+05</td><td>-4.27e+05</td></tr>
                                <tr><td>452.3</td><td>1032.0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>-2.05e+05</td><td>-4.69e+05</td></tr>
                                <tr><td>0</td><td>0</td><td>0</td><td>452.3</td><td>1032.0</td><td>1</td><td>-2.45e+05</td><td>-5.58e+05</td></tr>
                                <tr><td>411.4</td><td>1614.9</td><td>1</td><td>0</td><td>0</td><td>0</td><td>-1.89e+05</td><td>-7.43e+05</td></tr>
                                <tr><td>0</td><td>0</td><td>0</td><td>411.4</td><td>1614.9</td><td>1</td><td>-4.31e+05</td><td>-1.69e+06</td></tr>
                                <tr><td>776.0</td><td>1039.8</td><td>1</td><td>0</td><td>0</td><td>0</td><td>-6.11e+05</td><td>-8.19e+05</td></tr>
                                <tr><td>0</td><td>0</td><td>0</td><td>776.0</td><td>1039.8</td><td>1</td><td>-4.21e+05</td><td>-5.64e+05</td></tr>
                                <tr><td>795.5</td><td>1614.9</td><td>1</td><td>0</td><td>0</td><td>0</td><td>-6.25e+05</td><td>-1.27e+06</td></tr>
                                <tr><td>0</td><td>0</td><td>0</td><td>795.5</td><td>1614.9</td><td>1</td><td>-8.29e+05</td><td>-1.68e+06</td></tr>
                                <tr><td>1021.6</td><td>1299.1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>-1.03e+06</td><td>-1.30e+06</td></tr>
                                <tr><td>0</td><td>0</td><td>0</td><td>1021.6</td><td>1299.1</td><td>1</td><td>-8.05e+05</td><td>-1.02e+06</td></tr>
                            </tbody>
                        </table>
                    </div>
                    <span style="font-size: 2em; margin: 0 10px;">h =</span>
                    <div class="matrix-table">
                        <table>
                            <tbody>
                                <tr><td>425.1</td></tr>
                                <tr><td>20.1</td></tr>
                                <tr><td>1047.0</td></tr>
                                <tr><td>24.0</td></tr>
                                <tr><td>427.0</td></tr>
                                <tr><td>152.7</td></tr>
                                <tr><td>430.9</td></tr>
                                <tr><td>447.1</td></tr>
                                <tr><td>1050.9</td></tr>
                                <tr><td>170.3</td></tr>
                                <tr><td>1048.9</td></tr>
                                <tr><td>447.1</td></tr>
                                <tr><td>454.3</td></tr>
                                <tr><td>540.7</td></tr>
                                <tr><td>460.1</td></tr>
                                <tr><td>1047.6</td></tr>
                                <tr><td>787.7</td></tr>
                                <tr><td>542.6</td></tr>
                                <tr><td>785.7</td></tr>
                                <tr><td>1041.7</td></tr>
                                <tr><td>1004.1</td></tr>
                                <tr><td>788.3</td></tr>
                            </tbody>
                        </table>
                    </div>
                </div>

                <h3>Solved Homography</h3>
                <h4>Matrix H</h4>
                <div class="matrix-container">
                    <div class="matrix-table">
                        <table>
                            <tr><td>1.67e+00</td><td>3.90e-01</td><td>-4.24e+02</td></tr>
                            <tr><td>-6.15e-03</td><td>2.01e+00</td><td>-1.21e+03</td></tr>
                            <tr><td>2.18e-05</td><td>5.79e-04</td><td>1.00e+00</td></tr>
                        </table>
                    </div>
                </div>

                <h3>Warped Result</h3>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/A.2/1_projected.jpg" alt="Warped Image">
                        <figcaption>Image 1 Warped</figcaption>
                    </figure>
                </div>
            </section>

            <section class="project-section">
                <h2>A.3: Warping the Images & Rectification</h2>
                <p>I then wrote code to perform (inverse) warping given homographies.
                    In general, I took the convention that the top left pixel is (0, 0), and I used the inverse of the homography matrix to map pixels in the result to positions within the original image. I also calculated a bounding box to put the final warped image into by calculating the warped coordinates of the four corners of the rectangular picture.
                    I had two methods for warping:
                    <br>
                    Firstly, I had a method using the nearest neighbors strategy. Here, for each resulting pixel, I found the (continuous-valued) pixel coordinates in the original image that it maps to using the inverse of the homography matrix.
                    Then, I rounded those coordinates to the nearest integer coordinates, and, if within the range of the original image, took the value of that pixel.
                    <br>
                    I also implemented warping using bilinear interpolation. I started with a similar workflow to find the "original image coordinates" for each new image coordinate (by applying the inverse of the homography matrix), and then performed bilinear interpolation on the four pixels that form the square that emcompasses the current pixel, exactly as presented in class.
                    This was essentially a weighted average of those four pixels, with weight determined by how close it is to my mapped pixel.
                    <br><br>
                    Below are examples where I chose points on objects that are actually rectangles in the images, and then warped the image so that that object would appear as a rectangle. I performed both nearest neighbor and bilinear interpolation warping.
                    On small details, bilinear interpolation produced smoother results.
                    For example, towards the left hand side of the painting, nearest neighbor warping had small "blips", while bilinear interpolation was more smooth.
                    This effect is not that significant, though, and both methods provided visually reasonable images.
                    I suspect the contrast between the two might become more significant (with bilinear being more smooth) if the images I used were lower quality.
                    <br>
                    In terms of runtime, nearest neighbor warping was faster; for warpings that took around 30 seconds for nearest neighbor warping, bilinear interpolation took around 50 seconds.
                </p>

                <h3>Example 1</h3>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/A.3/1.jpg" alt="Original Image 1">
                        <figcaption>Original Image 1</figcaption>
                    </figure>
                </div>
                <div class="results-gallery">
                    <figure class="result-item">
                        <img src="./assets/A.3/1_nn.jpg" alt="Nearest Neighbor Result 1">
                        <figcaption>Nearest Neighbor Interpolation</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/A.3/1_bilinear.jpg" alt="Bilinear Result 1">
                        <figcaption>Bilinear Interpolation</figcaption>
                    </figure>
                </div>

                <h3>Example 2</h3>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/A.3/3.jpg" alt="Original Image 2">
                        <figcaption>Original Image 2</figcaption>
                    </figure>
                </div>
                <div class="results-gallery">
                    <figure class="result-item">
                        <img src="./assets/A.3/3_nn.jpg" alt="Nearest Neighbor Result 2">
                        <figcaption>Nearest Neighbor Interpolation</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/A.3/3_bilinear.jpg" alt="Bilinear Result 2">
                        <figcaption>Bilinear Interpolation</figcaption>
                    </figure>
                </div>
            </section>

            <section class="project-section">
                <h2>A.4: Blending Images into a Mosaic</h2>
                <p>I then used the previously written homography calculation as well as warping code to blend together some images into mosaics.
                    <br>
                    My workflow started with calculating the homography matrices; for each triplet, I calculated the homography matrix to warp from the left image's plane to the middle image's plane, and another homography matrix to warp from the right image's plane to the middle image's plane.
                    I accomplished this by choosing around 12 points of correspondencies between the left and the middle images, and then around 12 points of correspondencies between the middle and the right images, and calling the previously written homography calculation function.
                    <br>
                    Then, I actually warped the left and right images, also using the previously written warping code, as well as the homography matrices calculated just now.
                    <br>
                    Then, I determined the size of the mosaic that can fit all three images.
                    My warping code gives me the "offset" of the warped image in the coordinates of the middle image (basically, in the coordinates of the middle image, what are the coordinates of the top left corner of the projected/warped image), where I'm projecting everything to.
                    This allowed me to find the "minimum x and y coordinates" with any data, as well as the "maximum x and y coordinates" with any data, which gave me the size of the final mosaic.
                    With the information about the "offset", I was able to put the left, middle, and right images individually onto blank mosaics (of the correct size) at the correct locations.
                    <br>
                    With this, I then blended the images together. I accomplished this by using a weighted average between image pixels where images overlap; I blended together the left and middle images first, and then blended this result with the right image.
                    I followed the advice from lecture to use the "distance from each pixel to the closest pixel outside of the image" (referred to as edt from now on) to help. To calculate this per-pixel value for the left, middle, and right images, I used a separate mask that is 1.0 where the image is "defined" and 0.0 where the image is "undefined" instead of an alpha channel; I wrote a function to calculate this for all of the images.
                    I used scipy.ndimage.distance_transform_edt on those masks to calculate the edt's.
                    For the specifics of the weight distribution between the pixels from the two images when two images overlap, let d1 and d2 be the edt values of image1 and image2 at a specific pixel; image1's pixel's weight would be d1 / (d1 + d2 + eps) and image2's pixel's weight would be d2 / (d1 + d2 + eps), where eps is a small constant to avoid division by 0.
                    <br><br>
                    Overall, the main difficulty I encountered was choosing good points to make sure the homography is good between two images; I found that having a big positional "spread" of point correspondences is very important, in addition to the accuracy of the correspondences themselves.
                    <br>
                    See examples of mosaic blending below.
                </p>

                <h3>Set 1: Warren</h3>
                <div class="three-col-gallery">
                    <figure class="result-item">
                        <img src="./assets/sets/set1/1.jpg" alt="Warren Source 1">
                        <figcaption>Warren 1</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set1/2.jpg" alt="Warren Source 2">
                        <figcaption>Warren 2</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set1/3.jpg" alt="Warren Source 3">
                        <figcaption>Warren 3</figcaption>
                    </figure>
                </div>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/sets/set1/res.jpg" alt="Warren Mosaic">
                        <figcaption>Final Mosaic</figcaption>
                    </figure>
                </div>

                <h3>Set 2: BNorth</h3>
                <div class="three-col-gallery">
                    <figure class="result-item">
                        <img src="./assets/sets/set2/1.jpg" alt="BNorth Source 1">
                        <figcaption>BNorth 1</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set2/2.jpg" alt="BNorth Source 2">
                        <figcaption>BNorth 2</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set2/3.jpg" alt="BNorth Source 3">
                        <figcaption>BNorth 3</figcaption>
                    </figure>
                </div>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/sets/set2/res.jpg" alt="BNorth Mosaic">
                        <figcaption>Final Mosaic</figcaption>
                    </figure>
                </div>

                <h3>Set 3: Dwinelle</h3>
                <div class="three-col-gallery">
                    <figure class="result-item">
                        <img src="./assets/sets/set3/1.jpg" alt="Dwinelle Source 1">
                        <figcaption>Dwinelle 1</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set3/2.jpg" alt="Dwinelle Source 2">
                        <figcaption>Dwinelle 2</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/sets/set3/3.jpg" alt="Dwinelle Source 3">
                        <figcaption>Dwinelle 3</figcaption>
                    </figure>
                </div>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/sets/set3/res.jpg" alt="Dwinelle Mosaic">
                        <figcaption>Final Mosaic</figcaption>
                    </figure>
                </div>
            </section>

            <section class="project-section">
                <h2>B.1: Harris Corner Detection</h2>
                <p>For Part B, I worked on automating the point correspondence selection process for the images.
                    <br>
                    I started with Harris Corner detection, which takes into account gradients in multiple directions to detect corners.
                    I got the raw outputs of Harris Corner detection using the starter code given.
                    <br>
                    In order to make the runtime and space complexity of future stages of the pipeline (e.g. ANMS) more reasonable, I did a preliminary filtering on the Harris corners detected by passing in a min_distance value into the peak_local_max function in the starter code; I defined min_distance as the smaller of the image's dimensions divided by 100.
                    This significantly decreased the amount of harris corners detected, which is important for ANMS, because that part fills a matrix (e.g. distance matrix using dist2 given in the starter code) that scales quadratically with the amount of points.
                    <br>
                    For ANMS, I used dist2 to calculate the distances between all pairs of detected harris corners.
                    For each harris corner with "score" s1, I found the shortest distance from the corner to another corner with a "score" s2 for which s1 < c_robust * s2.
                    I used the paper's suggestion to use c_robust=0.9. I then sorted the points by this calculated "shortest distance", and returned the first "k" (default is 200) points.
                    This ensures that if two close corners are both "good" corners, that the one with slightly higher score won't disqualify the one with slightly lower score from being kept.
                    <br>
                    For the image on the right, I kept 200 points.
                </p>
                <div class="results-gallery">
                    <figure class="result-item">
                        <img src="./assets/B.1/total_points_colored.png" alt="Harris Corners without ANMS">
                        <figcaption>Raw Harris Corners</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/B.1/ANMS_points_colored.png" alt="Harris Corners with ANMS">
                        <figcaption>Harris Corners with ANMS</figcaption>
                    </figure>
                </div>
            </section>

            <section class="project-section">
                <h2>B.2: Feature Descriptor Extraction</h2>
                <p>After detecting the features, I then worked on "characterizing" the harris corners so I can find point correspondences.
                    <br>
                    Following the methods in the paper, for every harris corner, I subsampled an 8x8 square of pixels from the 40x40 surrounding square of pixels. I also normalized the features so that each feature has mean 0 and variance 1.
                    <br>
                    As the paper itself didn't mention blurring before subsampling, I did not initially blur before subsampling. Because the final results were good without blurring, I did not add blurring to my pipeline.
                    <br>
                    The following are some examples of feature descriptors. For each, the feature location is labeled in the original image using a red dot, and the feature itself is shown on the right.
                    <br>
                    The features make sense as a representation of the vacinity of the harris corner; for example, for the feature for the sign, there is a clear corner, with white on the bottom and gray on the right (for the shadow of the sign).
                </p>

                <div class="results-gallery">
                    <figure class="result-item">
                        <img src="./assets/B.2/corner1/point_original_pos_colored.png" alt="Feature 1 Location">
                        <figcaption>Right Sign Feature Location</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/B.2/corner1/feature.jpg" alt="Feature 1 Descriptor" class="pixelated">
                        <figcaption>Right Sign Feature Descriptor</figcaption>
                    </figure>
                </div>
                <div class="results-gallery">
                    <figure class="result-item">
                        <img src="./assets/B.2/corner2/point_original_pos_colored.png" alt="Feature 2 Location">
                        <figcaption>Vent Feature Location</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/B.2/corner2/feature.jpg" alt="Feature 2 Descriptor" class="pixelated">
                        <figcaption>Vent Feature Descriptor</figcaption>
                    </figure>
                </div>
                <div class="results-gallery">
                    <figure class="result-item">
                        <img src="./assets/B.2/corner3/point_original_pos_colored.png" alt="Feature 3 Location">
                        <figcaption>Left Door Feature Location</figcaption>
                    </figure>
                    <figure class="result-item">
                        <img src="./assets/B.2/corner3/feature.jpg" alt="Feature 3 Descriptor" class="pixelated">
                        <figcaption>Left Door Feature Descriptor</figcaption>
                    </figure>
                </div>
            </section>

            <section class="project-section">
                <h2>B.3: Feature Matching</h2>
                <p>After attaining a feature descriptor for each harris corner, I then proceeded to matching the corners between two images, so I can get point correspondences between two images.
                    <br>
                    To robustly retain the correct matches (without having the point correspondences being corrupted by incorrect matches), I employed the approach suggested by the paper.
                    In particular, for each feature in one of the images, I looked at the ratio between the Euclidian distances between the feature and its best match and the second best match in the other image.
                    If this ratio is small, that means that the best match is a lot better than the second best match. I chose a cutoff of 0.5 for this ratio, looking at the plot given in the paper.
                    <br>
                    Examples of results are shown below. Different types of images have different amounts of points: for more complex images such as set 2, there are more point correspondences; for less complex images such as set 3, there are less point correspondences.
                </p>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/B.3/output1.png" alt="Matched Features 1">
                        <figcaption>Matched Features Set 1 Left and Middle</figcaption>
                    </figure>
                </div>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/B.3/output2.png" alt="Matched Features 2">
                        <figcaption>Matched Features Set 2 Right and Middle</figcaption>
                    </figure>
                </div>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/B.3/output3.png" alt="Matched Features 3">
                        <figcaption>Matched Features Set 3 Left and Middle</figcaption>
                    </figure>
                </div>
            </section>

            <section class="project-section">
                <h2>B.4: RANSAC for Robust Homography</h2>
                <p>After attaining the points from feature matching from the previous stage, there were still points that were not correct matches.
                    I proceeded to solve this issue by using the RANSAC algorithm.
                    <br><br>
                    I repeatedly draw 4 point correspondencies at random, calculate a homography from them, and evaluate which other point correspondencies are consistent with this homography (the "inlier" set) by evaluating the magnitude of the difference between the point in the first image transformed by this homography and the corresponding point in the second image.
                    I set a cutoff (default is 5 pixels) for this magnitude.
                    I repeated this process for a set amount of times (default is 200 times), keeping track of the largest set of inliers, and returned that set in the end.
                    Below are examples comparing manual stitching with automatic stitching, with analysis given in the end. I used the same image sets as manual stitching, so for the raw image inputs, please see part A (A.1 or A.4).
                </p>

                <h3>Set 1: Warren</h3>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/sets/set1/res.jpg" alt="Warren Manual Mosaic">
                        <figcaption>Manual Stitching</figcaption>
                    </figure>
                </div>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/sets/set1/res_auto.jpg" alt="Warren Automatic Mosaic">
                        <figcaption>Automatic Stitching: ANMS points: 500, c_robust: 0.9, Lowe Threshold: 0.7<br>RANSAC iterations: 400, RANSAC cutoff: 7.0</figcaption>
                    </figure>
                </div>

                <h3>Set 2: BNorth</h3>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/sets/set2/res.jpg" alt="BNorth Manual Mosaic">
                        <figcaption>Manual Stitching</figcaption>
                    </figure>
                </div>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/sets/set2/res_auto.jpg" alt="BNorth Automatic Mosaic">
                        <figcaption>Automatic Stitching: ANMS points: 200, c_robust: 0.9, Lowe Threshold: 0.5<br>RANSAC iterations: 200, RANSAC cutoff: 5.0</figcaption>
                    </figure>
                </div>

                <h3>Set 3: Dwinelle</h3>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/sets/set3/res.jpg" alt="Dwinelle Manual Mosaic">
                        <figcaption>Manual Stitching</figcaption>
                    </figure>
                </div>
                <div class="single-image-container">
                    <figure class="result-item">
                        <img src="./assets/sets/set3/res_auto.jpg" alt="Dwinelle Automatic Mosaic">
                        <figcaption>Automatic Stitching: ANMS points: 200, c_robust: 0.9, Lowe Threshold: 0.5<br>RANSAC iterations: 200, RANSAC cutoff: 5.0</figcaption>
                    </figure>
                </div>
                <p>
                    Overall, the performance of automatic stitching was on par with the performance of manual stitching, though that is after my significant efforts to choose point correspondences with pixel-level accuracy.
                    Automatic stitching, though, was significantly less energy consuming on my part.
                    Further, for some sets of images (such as Set 3: Dwinelle), automatic stitching slightly outperformed manual stitching. For example, for the manually stitched mosaic, the right bar of the central frame was slightly blurry, whereas that for the automatically stitched mosaic was less blurry.
                </p>
            </section>
        </main>

        <footer>
            <p>&copy; 2025 Tiger Zhang. <a href="mailto:enming_zhang@berkeley.edu">Contact Me</a></p>
        </footer>
    </div>
</body>
</html>
